{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Associations of childhood and perinatal blood metals with childrenâ€™s gut microbiomes in a Canadian gestation cohort\n",
    "### Shen et al., 2022_Environmental Health Perspectives\n",
    "\n",
    "### This Jupyter notebook explains the high performance computing workflow of raw sequence data processing\n",
    "\n",
    "Note: Shotgun metagenome data is large, make sure you have enough space and memory for computing. If possible, use scratch space and later remove intermediate files. All scripts run in unix and python. All participants name is de-identified using \"SampleID\". All path to file is written as $path."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1: Clean up the raw sequence names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##cleanup names\n",
    "ls *gz|cut -f 1 -d \"_\" |uniq|while read line; do mv \"$line\"*_L001_R1_001.fastq.gz \"$line\"_L001_R1.fastq.gz;done\n",
    "ls *gz|cut -f 1 -d \"_\" |uniq|while read line; do mv \"$line\"*_L002_R1_001.fastq.gz \"$line\"_L002_R1.fastq.gz;done\n",
    "ls *gz|cut -f 1 -d \"_\" |uniq|while read line; do mv \"$line\"*_L001_R2_001.fastq.gz \"$line\"_L001_R2.fastq.gz;done\n",
    "ls *gz|cut -f 1 -d \"_\" |uniq|while read line; do mv \"$line\"*_L002_R2_001.fastq.gz \"$line\"_L002_R2.fastq.gz;done\n",
    "\n",
    "##merge L001&L002\n",
    "ls *gz|sort -t_ -k3|uniq|while read line1 && read line2; do cat \"$line1\" \"$line2\">../fastqmerge/\"$line1\"_merge.fastq.gz;done\n",
    "\n",
    "##cleanup names\n",
    "ls *gz|cut -f 1 -d \"_\" |uniq|while read line; do mv \"$line\"*_L001_R1.fastq.gz_merge.fastq.gz \"$line\"_R1.fastq.gz;done\n",
    "ls *gz|cut -f 1 -d \"_\" |uniq|while read line; do mv \"$line\"*_L001_R2.fastq.gz_merge.fastq.gz \"$line\"_R2.fastq.gz;done\n",
    "\n",
    "##Check file consistencies after merging and renaming\n",
    "#Check rename loop difference\n",
    "if diff /$path/SampleID_DNA_S72_L001_R1_001.fastq.gz \\\n",
    "/$path/SampleID_L001_R1.fastq.gz > /dev/null\n",
    "then\n",
    "    echo \"No difference\"\n",
    "else\n",
    "    echo \"Difference\"\n",
    "fi\n",
    "\n",
    "#returns no difference\n",
    "\n",
    "##Check merge loop difference\n",
    "# do several mannual merge and see difference\n",
    "cat /$path/SampleID_L001_R1.fastq.gz \\\n",
    "/$path/SampleID_L002_R1.fastq.gz >test1183_R1.fastq.gz\n",
    "\n",
    "if diff /$path/SampleID_R1.fastq.gz \\\n",
    "/$path/testSampleID_R1.fastq.gz > /dev/null\n",
    "then\n",
    "    echo \"No difference\"\n",
    "else\n",
    "    echo \"Difference\"\n",
    "fi\n",
    "#returns no difference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2: Quality Control raw reads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Fastqc and multiqc raw reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH --time=20:00:00\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --mem=50G\n",
    "#SBATCH --job-name=fastqc_geste\n",
    "\n",
    "cd /$path/fastqmerge\n",
    "mkdir FastQC_reports_geste\n",
    "export PATH=$PATH:/mnt/home/shenyike/shotguntest/FastQC/\n",
    "ls *fastq.gz|while read line; do fastqc -o FastQC_reports_geste/ -t 28 \"$line\";done\n",
    "\n",
    "scontrol show job $SLURM_JOB_ID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiqc .\n",
    "#Download multiqc html report to confirm what adapter sequencing center used for the next step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Trim adapters and start/end reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH --time=40:00:00\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --mem=50G\n",
    "#SBATCH --job-name=geste_trimmomatic\n",
    "\n",
    "cd /$path/fastqmerge_trim\n",
    "\n",
    "ls *gz|cut -f 1 -d \"_\" |uniq|while read line; do java -jar /opt/software/Trimmomatic/0.39-Java-1.8/trimmomatic-0.39.jar \\\n",
    "PE -phred33 \"$line\"_R1.fastq.gz \"$line\"_R2.fastq.gz ../QC_data/\"$line\"_R1.fastq.gz \\\n",
    "../QC_data/\"$line\".qcup_R1.fastq.gz ../QC_data/\"$line\"_R2.fastq.gz ../QC_data/\"$line\".qcup_R2.fastq.gz \\\n",
    "ILLUMINACLIP:/opt/software/Trimmomatic/0.39-Java-1.8/adapters/NexteraPE-PE.fa:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:36;done\n",
    "                                    \n",
    "scontrol show job $SLURM_JOB_ID\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Fastqc and multiqc trimmed reads & check quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH --time=20:00:00\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --mem=50G\n",
    "#SBATCH --job-name=fastqc_trimmed_geste\n",
    "\n",
    "cd /$path/fastqmerge\n",
    "mkdir FastQC_reports_geste\n",
    "export PATH=$PATH:/mnt/home/shenyike/shotguntest/FastQC/\n",
    "ls *fastq.gz|while read line; do fastqc -o FastQC_reports_geste/ -t 28 \"$line\";done\n",
    "\n",
    "scontrol show job $SLURM_JOB_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiqc .\n",
    "#Download multiqc html report to check the quality of QC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step3: Remove host reads (human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#human genome download from bowtie (already built)\n",
    "wget https://genome-idx.s3.amazonaws.com/bt/GRCh38_noalt_as.zip\n",
    "\n",
    "# One sample, \n",
    "# Please note, each sample takes 2.5-4.5 hours to run, it is more practical to submit multiple batch jobs. \n",
    "#Below batch script    \n",
    "\n",
    "#!/bin/bash\n",
    "#SBATCH --time=5:00:00\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --mem=100G\n",
    "#SBATCH --job-name=bowtie2_SampleID\n",
    "export PATH=$PATH:/mnt/home/shenyike/miniconda3/bin\n",
    "\n",
    "cd /$path/metagenome_GESTE2020/GRCh38_noalt_as\n",
    "\n",
    "bowtie2 -x GRCh38_noalt_as \\\n",
    "-1 /$path/metagenome_GESTE2020/QC_data/SampleID_R1.fastq.gz \\\n",
    "-2 /$path/metagenome_GESTE2020/QC_data/SampleID_R2.fastq.gz \\\n",
    "-S SampleID.sam --threads 28 \\\n",
    "--un-conc-gz /mnt/ls15/scratch/users/shenyike/metagenome_GESTE2021/fastq_dehost/SampleID.dehost.fq.gz\n",
    "\n",
    "scontrol show job $SLURM_JOB_ID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the below loop to generate #N batch jobs with different Sample ID and submit all jobs same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mkdir sbatch_folder_dehost #make directory in local computer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "name_index = pd.read_excel('File_Contain_Sample_List',header = None)\n",
    "name_index = np.array(name_index[0])\n",
    "\n",
    "s = ['#!/bin/bash','#SBATCH --time=5:00:00','#SBATCH --ntasks=1','#SBATCH --cpus-per-task=2',\n",
    "     '#SBATCH --mem=100G']\n",
    "for i in name_index:\n",
    "    with open('sbatch_folder_dehost/'+'dehost_'+str(i)+'.sbatch','w') as file:\n",
    "        for s_text in s:\n",
    "            file.write(s_text)\n",
    "            file.write('\\n')\n",
    "        file.write('#SBATCH --job-name=dehost_'+str(i))\n",
    "        file.write('\\n')\n",
    "        file.write('\\n')\n",
    "        file.write('\\n')\n",
    "        file.write('export PATH=$PATH:/mnt/home/shenyike/miniconda3/bin')\n",
    "        file.write('\\n')\n",
    "        file.write('\\n')\n",
    "        file.write('cd /$path/metagenome_GESTE2020/GRCh38_noalt_as')\n",
    "        file.write('\\n')\n",
    "        file.write('\\n')\n",
    "        cmd = 'bowtie2 -x GRCh38_noalt_as -1 /$path/metagenome_GESTE2020/QC_data/'+str(i)+'_R1.fastq.gz -2 /mnt/ls15/scratch/users/shenyike/metagenome_GESTE2021/QC_data/'+str(i)+'_R2.fastq.gz -S '+str(i)+'.sam --threads 28 --un-conc-gz /mnt/ls15/scratch/users/shenyike/metagenome_GESTE2021/fastq_dehost/'+str(i)+'.dehost.fq.gz'\n",
    "        file.write(cmd)\n",
    "        file.write('\\n')\n",
    "        file.write('\\n')\n",
    "        file.write('\\n')\n",
    "        file.write('scontrol show job $SLURM_JOB_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HAVE all batches in the same folder\n",
    "ls *|while read line;do sbatch \"$line\"; done\n",
    "#Cleanup names\n",
    "ls *gz|cut -d \".\"  -f 1|sort -t. -k1|while read line1; do mv \"$line1\"*1* \"$line1\"_dehost_R1.fastq.gz;read line2;mv \"$line2\"*2*  \"$line2\"_dehost_R2.fastq.gz;done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Humann3 mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One sample\n",
    "\n",
    "#Below batch scripts\n",
    "#!/bin/bash\n",
    "#SBATCH --time=24:00:00\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --mem=100G\n",
    "#SBATCH --job-name=humann_SampleID\n",
    "\n",
    "export OMP_NUM_THREADS=4\n",
    "conda init bash\n",
    "export CONDA3PATH=/mnt/home/shenyike/anaconda3\n",
    "module load Conda/3\n",
    "conda activate biobakery3\n",
    "\n",
    "cd /$path_to_host_removed_reads\n",
    "\n",
    "humann_config --update database_folders nucleotide /mnt/home/shenyike/.local/lib/python3.6/site-packages/metaphlan/metaphlan_databases/chocophlan\n",
    "\n",
    "humann_config --update database_folders protein /mnt/home/shenyike/.local/lib/python3.6/site-packages/metaphlan/metaphlan_databases/uniref\n",
    "\n",
    "humann_config --update database_folders utility_mapping /mnt/home/shenyike/.local/lib/python3.6/site-packages/metaphlan/metaphlan_databases/utility_mapping\n",
    "\n",
    "humann -i SampleID_dehost.fastq.gz -o humann_results/humann_SampleID --threads 4\n",
    "\n",
    "conda deactivate\n",
    "\n",
    "scontrol show job $SLURM_JOB_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the below loop to generate #N batch jobs with different Sample ID and submit all jobs same time\n",
    "#Humann runs more than 12 hours per sample, request enough run time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "name_index = pd.read_excel('File_Contain_Sample_List',header = None)\n",
    "name_index = np.array(name_index[0])\n",
    "\n",
    "\n",
    "s = ['#!/bin/bash','#SBATCH --time=24:00:00','#SBATCH --ntasks=1','#SBATCH --cpus-per-task=2',\n",
    "     '#SBATCH --mem=100G']\n",
    "for i in name_index:\n",
    "    with open('sbatch_folderhumann/'+'humann_'+str(i)+'.sbatch','w') as file:\n",
    "        for s_text in s:\n",
    "            file.write(s_text)\n",
    "            file.write('\\n')\n",
    "        file.write('#SBATCH --job-name=humann_'+str(i))\n",
    "        file.write('\\n')\n",
    "        file.write('\\n')\n",
    "        file.write('export OMP_NUM_THREADS=4')\n",
    "        file.write('\\n')\n",
    "        file.write('conda init bash')\n",
    "        file.write('\\n')\n",
    "        file.write('export CONDA3PATH=/mnt/home/shenyike/anaconda3')\n",
    "        file.write('\\n')\n",
    "        file.write('module load Conda/3')\n",
    "        file.write('\\n')\n",
    "        file.write('conda activate biobakery3')\n",
    "        file.write('\\n')\n",
    "        file.write('\\n')\n",
    "        file.write('cd $path_to_host_removed_reads')\n",
    "        file.write('\\n')\n",
    "        file.write('\\n')\n",
    "        cmd1='humann_config --update database_folders nucleotide /mnt/home/shenyike/.local/lib/python3.6/site-packages/metaphlan/metaphlan_databases/chocophlan'\n",
    "        file.write(cmd1)\n",
    "        file.write('\\n')\n",
    "        file.write('\\n')\n",
    "        cmd2='humann_config --update database_folders protein /mnt/home/shenyike/.local/lib/python3.6/site-packages/metaphlan/metaphlan_databases/uniref'\n",
    "        file.write(cmd2)\n",
    "        file.write('\\n')\n",
    "        file.write('\\n')\n",
    "        cmd3='humann_config --update database_folders utility_mapping /mnt/home/shenyike/.local/lib/python3.6/site-packages/metaphlan/metaphlan_databases/utility_mapping'\n",
    "        file.write(cmd3)\n",
    "        file.write('\\n')\n",
    "        file.write('\\n')\n",
    "        cmd4= 'humann -i '+str(i)+'_dehost.fastq.gz'+' -o humann_results/humann_'+str(i)+' --threads 4'\n",
    "        file.write(cmd4)\n",
    "        file.write('\\n')\n",
    "        file.write('\\n')\n",
    "        file.write('conda deactivate')\n",
    "        file.write('\\n')\n",
    "        file.write('\\n')\n",
    "        file.write('scontrol show job $SLURM_JOB_ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we have obtained pathway and gene-family table as main output; MetaPhlAn table in the intermediate output.\n",
    "#### Transform them to relative abundance following biobakery instructions for downstream analysis. \n",
    "#### Please install all dependencies following developers instructions:\n",
    "- FastQC and multiQC\n",
    "- Trimmomatic\n",
    "- Bowtie2\n",
    "- Humann3\n",
    "- Conda\n",
    "\n",
    "### Please refer to R scripts for downstream analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
